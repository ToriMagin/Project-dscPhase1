{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](images/director_shot.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Analysis\n",
    "\n",
    "Aurthor: Tori Magin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview & Business Problem\n",
    "\n",
    "Microsoft sees big companies creating original video content and they want to do get in on the action. They've decided to a create a new movie studio, but donâ€™t know what type of movies they should make. \n",
    "\n",
    "Without a solid understanding of the current movie landscape, Microsoft will not be able to make confident decisions on content creation. Therefore, this analysis will use data from online data bases, IMDB and Box Office Mojo, to identify trends and highlight elements that typically make a movie successful. For example, does critical acclaim (high ratings) translate to higher revenue. \n",
    "\n",
    "*For this analysis 'success' is defined as box office revenue, i.e., 'gross'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data & Method \n",
    "\n",
    "The data for this analysis came IMDB and Box Office Mojo as they have large databases, tracking many features of each movie. For example, IMDB can collate a large number of online reviews from a wide variety of sources to provide a representative average rating. \n",
    "\n",
    "The IMDB data (includes two data sets - \"Basics\" and \"Ratings\") describes the movie titles, release year, genres, running time, and ratings for movies from 2010 to present including future releases. \n",
    "\n",
    "The Box Office Mojo data details the domestic (US) and foreign gross each movie earned from 2010 to 2018. \n",
    "\n",
    "Only movie data from 2015 to 2022 was analysed to focus on the most recent and relevant trends. The average ratings, genres, and runtimes were  compared against the movies' total gross (combined domestic(US) and foreign gross) to identify elements of success. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/zippedData/imdb.title.basics.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m basics \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/zippedData/imdb.title.basics.csv.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m gross \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/zippedData/bom.movie_gross.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m ratings \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/zippedData/imdb.title.ratings.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\site-packages\\pandas\\io\\common.py:714\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m     handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    715\u001b[0m         filename\u001b[38;5;241m=\u001b[39mhandle,\n\u001b[0;32m    716\u001b[0m         mode\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    718\u001b[0m     )\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    726\u001b[0m     )\n",
      "File \u001b[1;32m~\\anacondaX\\lib\\gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/zippedData/imdb.title.basics.csv.gz'"
     ]
    }
   ],
   "source": [
    "basics = pd.read_csv(\"data/zippedData/imdb.title.basics.csv.gz\")\n",
    "gross = pd.read_csv(\"data/zippedData/bom.movie_gross.csv.gz\")\n",
    "ratings = pd.read_csv(\"data/zippedData/imdb.title.ratings.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The largest data set, IMDB Basics, was filtered to records from 2015 - 2022 to remove old and future data which could be unreliable or irrelevant. It was then merged with IMDB Ratings on 'tconst' the IMDB unique movie ID to make bnr (Basics 'n' Ratings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics['start_year_real']=pd.to_datetime(basics['start_year'], format='%Y')\n",
    "recent_basics = basics.drop(basics[basics['start_year'] < 2015].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_basics = recent_basics.drop(recent_basics[recent_basics['start_year'] > 2022].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " recent_basics = recent_basics.set_index('tconst')\n",
    "ratings = ratings.set_index('tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr = pd.merge(recent_basics,ratings, on=['tconst'],how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To merge with Box Office Mojo's Movie Grossï¼Œ the 'primary title' column was renames 'title' to provide a common column to merge. \n",
    "bnr.rename(columns = {'primary_title':'title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gross was merged on to the new bnr data frame, however the new data frame (bnr_2) had a lot of missing gross values. \n",
    "Any records missing domestic_gross values were dropped. Because ~80% of the records had no domestic_gross value, they could not be reliably filled with placeholder values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2 = pd.merge(bnr,gross, on=['title'],how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2.dropna(subset=['domestic_gross'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was considered to also drop all foreign_gross null values, but this would result it too much data loss and the percentage of missing values was a more acceptable 43.7%, so it was decided to fill the null values with the foreign_gross median. The median was calculated using the original 'gross' dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2['foreign_gross'].isna().sum() /  (bnr_2['foreign_gross'].count()+bnr_2['foreign_gross'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross.dropna(subset=['foreign_gross'], inplace=True)\n",
    "gross['foreign_gross'] = gross['foreign_gross'].map(lambda x: x.replace(',',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross.iloc[1300:1303]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atfer removing the commas, the values can be converted to floats. However, it's clear these numbers are not correctly formatted. \n",
    "Because there is only three, I manually replaced the values with the true foreign gross. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross['foreign_gross']= gross['foreign_gross'].replace([1131.6],1131561399)\n",
    "gross['foreign_gross']= gross['foreign_gross'].replace([1019.4],1018130012)\n",
    "gross['foreign_gross']= gross['foreign_gross'].replace([1163.0],1162040651)\n",
    "gross.iloc[1300:1305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross['foreign_gross']= gross['foreign_gross'].astype('float')\n",
    "f_gross_median = gross['foreign_gross'].median()\n",
    "bnr_2['foreign_gross'] = bnr_2['foreign_gross'].fillna(f_gross_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bnr_2 data set also had ',' values, these I replaced by correcting the decimal point position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2['foreign_gross']= bnr_2['foreign_gross'].replace(['1,131.6'],1131561399)\n",
    "bnr_2['foreign_gross']= bnr_2['foreign_gross'].replace(['1,019.4'],1018130012)\n",
    "bnr_2['foreign_gross']= bnr_2['foreign_gross'].replace(['1,163.0'],1162040651)\n",
    "bnr_2['foreign_gross']= bnr_2['foreign_gross'].replace(['1,369.5'],1369500000)\n",
    "bnr_2['foreign_gross']= bnr_2['foreign_gross'].replace(['1,010.0'],1010000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2['foreign_gross'] = bnr_2['foreign_gross'].astype('float')\n",
    "bnr_2['total_gross'] = bnr_2['domestic_gross'] + bnr_2['foreign_gross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#26 records had no genre, so it is easiest to remove this small number of records with missing info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2= bnr_2.dropna(subset=['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2['genreslist'] = bnr_2['genres'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bnr_2['genres'].map(lambda x: x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2.sort_values('start_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "\n",
    "The average ratings, genres, and runtimes were compared against the movies' total gross (combined domestic (US) and foreign gross) to identify elements of success. \n",
    "\n",
    "The data was separated into Top 100 Movies (highest total gross) and Bottom 100 Movies (lowest total gross) to provide two comparative sample sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Analysis by Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings of the top and bottom 100 movies (by total gross) were examined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_gross = bnr_2.sort_values('total_gross', ascending=False)\n",
    "top_100 = by_gross['total_gross'][0:100]\n",
    "top_100 = list(top_100)\n",
    "\n",
    "len(top_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_100 = by_gross['averagerating'][0:100]\n",
    "best_100 = list(best_100)\n",
    "\n",
    "len(best_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_gross = bnr_2.sort_values('total_gross')\n",
    "bottom_100 = bottom_gross['total_gross'][0:100]\n",
    "bottom_100 = list(bottom_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_100 = bottom_gross['averagerating'][0:100]\n",
    "worst_100 = list(worst_100)\n",
    "\n",
    "len(worst_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = pd.DataFrame()\n",
    "tops['Gross'] = top_100\n",
    "tops['AvgRatings'] = best_100\n",
    "tops = tops.dropna()\n",
    "\n",
    "TopRatingsCor = tops.corr(method='pearson')\n",
    "TopRatingsCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorrelationDF = pd.DataFrame()\n",
    "CorrelationDF['gross'] = bnr_2['total_gross']\n",
    "CorrelationDF['Avg_Rating'] = bnr_2['averagerating']\n",
    "CorrelationDF['runtime'] = bnr_2['runtime_minutes']\n",
    "\n",
    "CorrelationDF\n",
    "correlation = CorrelationDF.corr(method='pearson')\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " AVG Rating Vs Gross Scatter Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(figsize=(11,4), ncols=2)\n",
    "\n",
    "ax1.scatter(x=top_100, y=best_100, color='purple', marker='h')\n",
    "ax1.set_xlabel('Total Gross ($ Bil)', fontsize=13)\n",
    "ax1.set_ylabel('Avg Rating',  fontsize=13)\n",
    "ax1.set_title('Top 100 Movies by Gross', fontsize=14)\n",
    "\n",
    "\n",
    "ax2.scatter(x=bottom_100, y=worst_100,color='darkcyan', marker='h')\n",
    "ax2.set_xlabel('Total Gross ($ Mil)', fontsize=13)\n",
    "ax2.set_ylabel('Avg Rating',  fontsize=13)\n",
    "ax2.set_title('Bottom 100 Movies by Gross', fontsize=14)\n",
    "\n",
    "fig.suptitle(\"Avg Ratings Vs Total Gross\", fontsize=24, x=0.51, y=1.1)\n",
    "\n",
    "plt.savefig('./images/RatingsGrossScatter.png', bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analysis by Runtime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_runtime = bnr_2.sort_values('total_gross', ascending=False)\n",
    "Time_top_100 = top_by_runtime['runtime_minutes'][0:100]\n",
    "Time_top_100 = list(Time_top_100)\n",
    "\n",
    "Top_Avg_Runtime = (str(sum(Time_top_100) / 100) + \" mins\")\n",
    "\n",
    "Top_Avg_Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopRuntime = pd.DataFrame()\n",
    "TopRuntime['Gross'] = top_100\n",
    "TopRuntime['Runtime'] = Time_top_100 \n",
    "\n",
    "TopRuntime = TopRuntime.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_by_runtime = bnr_2.sort_values('total_gross')\n",
    "Time_bottom_100 = bottom_by_runtime['runtime_minutes'][0:100]\n",
    "Time_bottom_100 = list(Time_bottom_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BottomsRuntime = pd.DataFrame()\n",
    "BottomsRuntime['Gross'] = bottom_100\n",
    "BottomsRuntime['Runtime'] = Time_bottom_100 \n",
    "\n",
    "BottomsRuntime = BottomsRuntime.dropna()\n",
    "\n",
    "Avg_Bottom_Runtime = BottomsRuntime['Runtime'].mean()\n",
    "Avg_Bottom_Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Runtime Vs Gross Scatter Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax3, ax4) = plt.subplots(figsize=(11,4), ncols=2)\n",
    "\n",
    "ax3.scatter(x=top_100, y=Time_top_100, color='purple', marker='h')\n",
    "ax3.set_title('Top 100 Movies by Gross', fontsize = 14)\n",
    "ax3.set_xlabel('Total Gross ($ Bil)', fontsize = 13)\n",
    "ax3.set_ylabel('Runtime (minutes)', fontsize = 12)\n",
    "\n",
    "\n",
    "ax4.scatter(x=bottom_100, y=Time_bottom_100,color='darkcyan', marker='h')\n",
    "ax4.set_title('Bottom 100 Movies by Gross', fontsize = 14)\n",
    "ax4.set_xlabel('Total Gross ($ Mil )', fontsize = 13)\n",
    "ax4.set_ylabel('Runtime (minutes)', fontsize = 12)\n",
    "\n",
    "plt.savefig('./images/RuntimeGrossScatter.png', bbox_inches = \"tight\")\n",
    "\n",
    "fig.suptitle(\"Runtime Vs Gross\", fontsize=24, x=0.51, y=1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis by Genre \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_by_gross = bnr_2.sort_values('total_gross', ascending=False)\n",
    "bnr_top100_by_gross = bnr_by_gross[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_genres = \"\"\n",
    "for x in bnr_top100_by_gross['genreslist']:\n",
    "    Top_genres += str(x) + \",\"\n",
    "Top_genres = Top_genres.split(',')\n",
    "\n",
    "len(Top_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "top_counts_average = Counter(Top_genres).most_common()\n",
    "print(top_counts_average)\n",
    "type(top_counts_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = []\n",
    "for x in top_counts_average:\n",
    "    top_names.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = []\n",
    "for x in top_counts_average:\n",
    "    top_values.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_by_gross_bottom = bnr_2.sort_values('total_gross')\n",
    "bnr_bottom100_by_gross = bnr_by_gross_bottom[0:100]\n",
    "\n",
    "len(bnr_bottom100_by_gross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_genres = \"\"\n",
    "for x in bnr_bottom100_by_gross['genreslist']:\n",
    "    bottom_genres += str(x) + \",\"\n",
    "bottom_genres = bottom_genres.split(',')\n",
    "\n",
    "len(bottom_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bottom_counts_average = Counter(bottom_genres).most_common()\n",
    "bottom_counts_average = bottom_counts_average[0:20]\n",
    "len(bottom_counts_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_names = []\n",
    "for x in bottom_counts_average:\n",
    "    bottom_names.append(x[0])\n",
    "\n",
    "bottom_names = bottom_names[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_values = []\n",
    "for x in bottom_counts_average:\n",
    "    bottom_values.append(x[1])\n",
    "\n",
    "bottom_values = bottom_values[0:20]\n",
    "print(bottom_names)\n",
    "print(bottom_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genre & Gross - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (gt,gb) = plt.subplots(figsize=(15,6), ncols=2)\n",
    "\n",
    "gt.bar(range(len(top_counts_average)), top_values, color=('purple'), tick_label=top_names)\n",
    "plt.xticks(rotation = 90)\n",
    "gt.set_ylabel('Number of movies', fontsize=14)\n",
    "gt.set_xlabel('Genres')\n",
    "gt.set_title('Top 100 Movie - Genres', fontweight=\"bold\", fontsize =16)\n",
    "\n",
    "\n",
    "gb.bar(range(len(bottom_counts_average)), bottom_values,color=('darkcyan'), tick_label=bottom_names)\n",
    "plt.xticks(rotation=90)\n",
    "gb.set_ylabel('Number of movies', fontsize=14)\n",
    "gb.set_xlabel('Genres')\n",
    "gb.set_title('Bottom 100 Movie - Genres', fontweight=\"bold\",  fontsize =16)\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/Genres_Top_n_Bottom.png', bbox_inches = \"tight\")\n",
    "plt.show();\n",
    "\n",
    "fig.suptitle('Common Genres for the Top & Bottom Movie Lists', fontsize = '24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying Top Studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_studios = \"\"\n",
    "for x in bnr_top100_by_gross['studio']:\n",
    "    Top_studios += str(x) + \",\"\n",
    "Top_studios = Top_studios.split(',')\n",
    "\n",
    "len(Top_studios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topS_counts_average = Counter(Top_studios).most_common()\n",
    "print(topS_counts_average)\n",
    "type(topS_counts_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topS_names = []\n",
    "for x in topS_counts_average:\n",
    "    topS_names.append(x[0])\n",
    "len(topS_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topS_values = []\n",
    "for x in topS_counts_average:\n",
    "    topS_values.append(x[1])\n",
    "len(topS_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bottom_studios = \"\"\n",
    "for x in bnr_bottom100_by_gross['studio']:\n",
    "    Bottom_studios += str(x) + \",\"\n",
    "Bottom_studios = Bottom_studios.split(',')\n",
    "\n",
    "len(Bottom_studios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bottomS_counts_average = Counter(Bottom_studios).most_common()\n",
    "type(bottomS_counts_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottomS_names = []\n",
    "for x in bottomS_counts_average:\n",
    "    bottomS_names.append(x[0])\n",
    "len(bottomS_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottomS_values = []\n",
    "for x in bottomS_counts_average:\n",
    "    bottomS_values.append(x[1])\n",
    "len(bottomS_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Studios = pd.DataFrame()\n",
    "Top_Studios['StudioName'] = topS_names\n",
    "Top_Studios['#_of_Top100_Movies'] = topS_values\n",
    "\n",
    "Top_Studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bottom_Studios = pd.DataFrame()\n",
    "Bottom_Studios['StudioName'] = bottomS_names\n",
    "Bottom_Studios['#_of_Bottom100_Movies'] = bottomS_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_2.sort_values('start_year', ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "Overall, the above data modelling does provide some useful insights, such as what genre of films to focus on and avoid. However, there's still many unknow factors for further analysis. For example, the movie production  costs are unknown, so we cannot examine net profit or loss. \n",
    "\n",
    "With more time, I would also run the same analysis over larger samples, for exmaple Top and Bottom 300 (which is approx. 20% of BNR_2). This may provide better generalisation of results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "1. Microsoft should not try to make content decisions based on potential movie ratings as:\n",
    "  - The impact of ratings on gross is rather minor, and; \n",
    "  - A studio has limited direct control over future reviews.  \n",
    "2. The runtime influence is also minor, but it is worth noting the significant difference in average runtime between Top and Bottom 100 Movies. This indicates audiences prefer longer, epic-like movies and is an area Microsoft should research for further insights. \n",
    "\n",
    "3. Microsoft should focus on action and adventure movies and avoid dramas and documentaries. The clearest distinction between the Top and Bottom 100 is the composition of genre, so this area should be considered most seriously.\n",
    "\n",
    "4. Microsoft could consider the list of studios that produced the Top 100 and research further how these studios operate to gain insights on how successful movies are chosen and produced. \n",
    "\n",
    "\n",
    "## Conclusion\n",
    "This analysis demonstrated the major factor influencing a movieâ€™s success is the genre. Audiences have a strong preference for action and adventure movies and, to a lesser extent, comedy and animation. \n",
    "This analysis only looked at movie gross. Further research should examine movies by net profit and less to gain a better understanding profitability. \n",
    "Other factors, ratings and runtime, were not strongly correlated with the total movie gross. \n",
    "\n",
    "## Next Steps\n",
    " 1. Conduct further research into movie production costs to understand the relationship between ratings, runtime, and genre and net profit or loss. \n",
    " \n",
    " 2. Explore other related factors to find stronger relationships. For example, the movie rating appeared to have little impact on movie gross, but number of reviews/ratings (i.e., level of media exposure) may be more impactful and worth examining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
